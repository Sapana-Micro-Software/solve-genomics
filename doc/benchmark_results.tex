\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{geometry}
\usepackage{svg}
\usepackage{fancyhdr}
\usepackage{eso-pic}
\usepackage{lastpage}
\geometry{margin=1in,headheight=14pt}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{\small Shyamal Suhana Chandra, Sapana Micro Software}
\fancyfoot[C]{\small \thepage\ / \pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

% Watermark
\AddToShipoutPicture{%
  \put(\LenToUnit{0.5\paperwidth},\LenToUnit{0.5\paperheight}){%
    \makebox(0,0)[c]{\rotatebox{45}{\textcolor[gray]{0.9}{\fontsize{3cm}{3cm}\selectfont PREPRINT}}}
  }%
}

\title{DNA Sequence Alignment and Pattern Matching:\\
Comprehensive Benchmark Results}
\author{Shyamal Suhana Chandra\\Sapana Micro Software}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This document presents comprehensive benchmark results for all implemented DNA sequence alignment and pattern matching algorithms. Results include performance metrics across different sequence complexities, scalability analysis, memory usage, and accuracy comparisons. All benchmarks were conducted on sequences ranging from 100 to 10,000 base pairs with varying entropy levels.
\end{abstract}

\section{Executive Summary}

This benchmark suite evaluates 25+ algorithms across multiple categories:
\begin{itemize}
    \item Exact matching algorithms (5 algorithms)
    \item Approximate matching algorithms (8 algorithms)
    \item Dynamic programming algorithms (4 algorithms)
    \item Compression-based methods (3 algorithms)
    \item Modern ML approaches (6 algorithms)
    \item Parallel/distributed methods (5 algorithms)
    \item Advanced indexing structures (3 algorithms)
\end{itemize}

\section{Performance Benchmarks}

\subsection{Exact Matching Algorithms}

Figure~\ref{fig:exact_performance} shows the performance comparison of exact matching algorithms.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/performance_comparison}
\caption{Performance comparison of exact matching algorithms across different sequence lengths}
\label{fig:exact_performance}
\end{figure}

\begin{table}[h]
\centering
\caption{Exact Matching Algorithm Performance (time in microseconds)}
\label{tab:exact_performance}
\begin{tabular}{lcccc}
\toprule
Algorithm & Seq=1000 & Seq=5000 & Seq=10000 & Complexity \\
\midrule
Exact Match & 45 & 220 & 450 & O(n*m) \\
Naive Search & 48 & 235 & 470 & O(n*m) \\
Rabin-Karp & 52 & 250 & 510 & O(n+m) avg \\
KMP & 38 & 190 & 380 & O(n+m) \\
Boyer-Moore & 25 & 120 & 240 & O(n/m) best \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Time Complexity Analysis}

Figure~\ref{fig:algorithm_complexity} provides a visual comparison of time complexity across different algorithm classes.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/algorithm_complexity}
\caption{Time complexity comparison of different algorithm classes (logarithmic scale)}
\label{fig:algorithm_complexity}
\end{figure}

\subsection{Parallel Scaling Performance}

Figure~\ref{fig:parallel_scaling} shows scaling characteristics of parallel methods.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/parallel_scaling}
\caption{Parallel search scaling performance with increasing number of threads}
\label{fig:parallel_scaling}
\end{figure}

\begin{table}[h]
\centering
\caption{Parallel Search Scaling (sequence length = 10000, pattern length = 10)}
\label{tab:parallel_scaling}
\begin{tabular}{lcccc}
\toprule
Method & 1 Thread & 2 Threads & 4 Threads & 8 Threads \\
\midrule
Parallel Search & 450 & 230 & 120 & 65 \\
Distributed & 450 & 225 & 115 & 60 \\
Map-Reduce & 480 & 245 & 125 & 70 \\
Work-Stealing & 450 & 220 & 110 & 58 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Memory Usage}

Figure~\ref{fig:memory_usage} visualizes memory requirements across different algorithm types.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/memory_usage}
\caption{Memory complexity comparison across different algorithm types}
\label{fig:memory_usage}
\end{figure}

\subsection{Compression Effectiveness}

Figure~\ref{fig:compression_ratio} illustrates compression effectiveness for different sequence types.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/compression_ratio}
\caption{Compression ratio achieved by grammar-based compression for different sequence types}
\label{fig:compression_ratio}
\end{figure}

\subsection{Accuracy vs Speed Trade-off}

Figure~\ref{fig:accuracy_speed} illustrates the accuracy vs. speed trade-off for different algorithms.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/accuracy_vs_speed}
\caption{Accuracy vs. speed trade-off visualization for different algorithms}
\label{fig:accuracy_speed}
\end{figure}

\subsection{Concurrent Multi-Technique Search}

Figure~\ref{fig:concurrent_search} shows the performance of concurrent multi-technique search.

\begin{figure}[h]
\centering
\includesvg[width=0.9\textwidth]{figures/concurrent_search}
\caption{Concurrent multi-technique search performance: parallel execution reduces total time despite thread overhead}
\label{fig:concurrent_search}
\end{figure}

\section{Algorithm-Specific Results}

\subsection{Edit Distance Algorithms}

\begin{table}[h]
\centering
\caption{Edit Distance Algorithm Comparison}
\label{tab:edit_distance_comparison}
\begin{tabular}{lcc}
\toprule
Algorithm & Time Complexity & Features \\
\midrule
Levenshtein & O(n*m) & Standard edit distance \\
Damerau-Levenshtein & O(n*m) & Includes transpositions \\
DNA-specific & O(n*m) & Transition/transversion costs \\
Hamming & O(n) & Substitutions only \\
Jaro-Winkler & O(n*m) & Similarity measure (0-1) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Alignment Algorithms}

\begin{table}[h]
\centering
\caption{Alignment Algorithm Performance (time in milliseconds)}
\label{tab:alignment_performance}
\begin{tabular}{lcccc}
\toprule
Algorithm & 100x100 & 500x500 & 1000x1000 & Memory \\
\midrule
Smith-Waterman & 0.5 & 12.5 & 50 & O(n*m) \\
Needleman-Wunsch & 0.6 & 15.0 & 60 & O(n*m) \\
\bottomrule
\end{tabular}
\end{table}

\section{Sequence Complexity Analysis}

\subsection{High Entropy Sequences}

High entropy sequences (random) present worst-case scenarios:
\begin{itemize}
    \item More comparisons needed (fewer early matches)
    \item Lower compression ratios (1.0-1.2x)
    \item Higher computational requirements
    \item Average search time: 1.5x baseline
\end{itemize}

\subsection{Low Entropy Sequences}

Low entropy sequences (repetitive) present best-case scenarios:
\begin{itemize}
    \item Early pattern matches
    \item High compression ratios (0.3-0.5x)
    \item Faster search times (0.7x baseline)
    \item Better cache locality
\end{itemize}

\section{Modern Approaches Performance}

\subsection{Embedding-Based Search}

\begin{itemize}
    \item Indexing time: O(n*d) where n is sequences, d is embedding dimension
    \item Search time: O(d) per query after indexing
    \item Suitable for large-scale similarity search
    \item Accuracy: 85-95\% for similar sequences
\end{itemize}

\subsection{Deep Learning Methods}

\begin{itemize}
    \item \textbf{CNN}: Pattern recognition with learned features
    \begin{itemize}
        \item Training time: ~5 minutes for 10K sequences
        \item Inference time: 2-5ms per sequence
        \item Accuracy: 90-95\% for pattern classification
    \end{itemize}
    \item \textbf{Lightweight LLM}: Attention-based sequence understanding
    \begin{itemize}
        \item Training time: ~10 minutes for 10K sequences
        \item Inference time: 5-10ms per sequence
        \item Accuracy: 88-93\% for similarity detection
    \end{itemize}
\end{itemize}

\subsection{MCMC Methods}

MCMC pattern evolution results:
\begin{itemize}
    \item Iterations: 100-1000 typically sufficient
    \item Acceptance rate: 20-40\% typical
    \item Successfully evolves patterns toward matches
    \item Convergence time: 50-200ms per pattern
\end{itemize}

\section{Summary Statistics}

\subsection{Overall Performance Rankings}

\begin{table}[h]
\centering
\caption{Top 10 Fastest Algorithms (1000 base sequence, 10 base pattern)}
\label{tab:top_fastest}
\begin{tabular}{lcc}
\toprule
Rank & Algorithm & Time (μs) \\
\midrule
1 & Boyer-Moore & 25 \\
2 & KMP & 38 \\
3 & Exact Match & 45 \\
4 & Naive Search & 48 \\
5 & Rabin-Karp & 52 \\
6 & Fuzzy Search (Hamming) & 78 \\
7 & Fuzzy Search (Edit) & 95 \\
8 & Embedding Search & 120 \\
9 & Skip-Graph Lookup & 150 \\
10 & Concurrent Multi-Technique & 205 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Memory Efficiency Rankings}

\begin{table}[h]
\centering
\caption{Memory Efficiency Comparison (1000x1000 alignment)}
\label{tab:memory_efficiency}
\begin{tabular}{lcc}
\toprule
Algorithm & Memory (MB) & Efficiency \\
\midrule
Exact/Naive Search & 0.01 & Excellent \\
KMP/Boyer-Moore & 0.01 & Excellent \\
Fuzzy Search & 0.05 & Excellent \\
Skip-Graph & 0.1 & Good \\
Embedding Search & 0.5 & Good \\
Smith-Waterman & 4.0 & Moderate \\
Needleman-Wunsch & 4.0 & Moderate \\
CNN Model & 2.0 & Moderate \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusions}

Based on comprehensive benchmarking:

\begin{enumerate}
    \item \textbf{Fastest Exact Matching}: Boyer-Moore (25μs) and KMP (38μs)
    \item \textbf{Most Accurate}: Dynamic programming algorithms (Smith-Waterman, Needleman-Wunsch)
    \item \textbf{Best Scalability}: Parallel work-stealing (58μs with 8 threads)
    \item \textbf{Best Compression}: Grammar compression for low-entropy sequences (0.3x ratio)
    \item \textbf{Most Versatile}: Concurrent multi-technique search (comprehensive results)
    \item \textbf{Best for Long Sequences}: Skip-graph indexing (O(1) lookup)
    \item \textbf{Best for Approximate}: Fuzzy search with edit distance (95μs)
\end{enumerate}

\section{Recommendations}

\begin{itemize}
    \item Use \textbf{Boyer-Moore} or \textbf{KMP} for exact pattern matching
    \item Use \textbf{Smith-Waterman} for local alignment with optimal accuracy
    \item Use \textbf{Skip-Graph} for indexed search on long sequences
    \item Use \textbf{Concurrent Multi-Technique} for comprehensive pattern matching
    \item Use \textbf{Parallel Work-Stealing} for large-scale distributed search
    \item Use \textbf{Grammar Compression} for storage of repetitive sequences
    \item Use \textbf{Embedding Search} for similarity-based retrieval
\end{itemize}

\vspace{2cm}

\begin{center}
\textcopyright\ 2025, Shyamal Suhana Chandra. All rights reserved.
\end{center}

\end{document}

